---
title: "Multiple Regression <br> Chapter 6.0 - 6.1"
institute: "Department of Statistics and Data Science <br> STAT 202"

logo: nu_logo.png
format: 
  revealjs:
    theme: [default, nu_theme.scss]
    chalkboard:
      theme: whiteboard
      toggleNotesButton: false
    menu:
        side: right
    code-line-numbers: false

execute:
  message: false
  warning: false
  echo: true
---

```{r}
#| include: false
library(ggplot2)
library(dplyr)
library(palmerpenguins)
```

## Today's goals {background-image="images_horst/comics/graphing_relationship.png" background-size="400px" background-opacity="50%" background-position="85% 50%"}

<br/>

::: columns
::: {.column width="60%"}
1.  Regression with two numerical explanatory variables
2.  Understand coefficient interpretation
3.  Make predictions with a model
:::
:::

## Multiple Regression

**Definition**: models the relationship between a response (y) variable and two or more explanatory (x) variables.

. . .

-   2 numerical explanatory variables this is the "plane" of best fit.
-   1 numerical + 1 categorical explanatory variable use a line of best fit separated by category.

. . .

**EDA**: Same as simple regression. Look at the raw data, calculate summary statistics/correlations, and use data visualizations.

## MLR Correlation and Causation

**Correlation**: calculate the correlation between each pair of variables.

```{r multreg-cor}
#| echo: true
penguins %>% 
  filter(!is.na(flipper_length_mm)) %>% 
  select(body_mass_g, flipper_length_mm, bill_length_mm) %>%
  cor()
```

<br>

. . .

**Causation**: any change in the value of one variable will cause a change in the value of another variable, which means one variable makes the other happen.

## Correlation does not mean causality!!

<center>![](images_lecture/icecream_drownings.png){#id .class width="650px" height="600px"}</center>

## Multiple Regression Modeling

Multiple regression is the procedure that helps us disentangle issues with confounding (lurking) variables. That is, a procedure that will help sort out collinearity issues.

. . .

-   **Simpson's paradox**: a trend appears in several groups of data but the trend disappears or reverses when groups are combined.

. . .

-   **Model**: In multiple linear regression, the significance of each term in the model depends on the other terms in the model.

## Example: model

Predict body mass based on both flipper length and bill length.

```{r multreg-model}
#| echo: true
model_penguins <- lm(body_mass_g ~ flipper_length_mm + bill_length_mm, data = penguins)
summary(model_penguins)$coefficients
```

. . .

$$\widehat{bodymass} = b_0 +b_1*\text{flipper} + b_2*\text{bill_length}$$

## Example: interpretations

$$\widehat{bodymass} = -5736.9 + 48.14*\text{flipper} + 6.05*\text{bill_length}$$

::: incremental
-   $b_0$ intercept; the **predicted/expected** body mass when a penguin has flipper length 0 and bill length 0
-   $b_1$ slope of flipper length; taking into account all other explanatory variables, for every 1 mm increase in flipper length, the **expected** body mass increases by $48.14$
-   $b_2$ slope of bill length; taking into account all other explanatory variables, for every 1 mm increase in bill length, the **expected** body mass increases by $6.05$
:::

## Example: prediction

::: {.absolute top="0%" left="90%" width="100"}
![](images_lecture/participate_icon.png)
:::

$$\widehat{bodymass} = -5736.9 + 48.14*\text{flipper} + 6.05*\text{bill_length}$$

<br>

You recently got a penguin and measured their **flipper_length** to be 150mm and their **bill_length** to be 40mm. What do you expect their body mass to be?
